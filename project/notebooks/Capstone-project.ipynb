{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crowdfunding has become a new and exciting way to get capitale and to invest. Lending club has jumped into the trend by offering loans with fixed interest rates and terms that the public can choose to invest in. Lending club screens the loans that are applied for and only 10% gets approved and is subsequently offered to the public. By investing a small proportion in many different loans investors can diversify their portfolio and in this way keep the default risk to a minimum (which is estimated by lending club to be 4%). For their services lending club asks a fee of 1%. For investors this is an interesting way to get profit on their investment since it supposedly gives more stable returns than the stock market and higher interest rates than a savings account. The profits depend on the interest rate and the default rate. Therefore it is interesting to see whether certain characteristics of the loan or the buyer give a bigger chance of default. Hence this might help investors to upgrade their profits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lending club has provided the public with their records via their website. A previous dataset was released that holds the records from 2007-2011 and there has also been a Kaggle contest with a preprocessed lending club dataset in the past. In April 2016 lending club has provided their 2007-2015 dataset through Kaggle as dataset, not as contest. This is the dataset we will be working on with in this project. Nevertheless, previous work has usually been done on one of the earlier releases of their dataset. While most earlier work has been focussed on predicting good loans from bad loans which we also will be focussing on, most have incorporated also the current loans. This holds a problem, since loans with a 'late' status could still recover and end in 'fully paid'. And 'current' loans could still end in the status 'charged off'. This is why we will focus only on loans that are closed and are therefore either 'fully paid' or 'charged off'. The consequence is that previous work that has incorporated these current loans is not completely comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict whether a loan will end in 'charged off' we will use machine learning algorithms. According to previous work, both Logistic Regression and Random Forest have been found to work the best. Although work that incorporates no external datasets usually ends up with a Area Under the Curve (AUC)-score around 0.7. Which is not really great, but better than chance. The most important feature is usually found to be 'grade'. This is a measure for risk assesment of the loans given by Lending Club itself. The categories are A-G including subcategories like A1 etc. The idea is that the closer to G the higher the chance on default. Usually the interest rate is also higher for the riskier loans in order to make these loans still attractive for investors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will first focus on exploring the data. We will see whether Lending Club is right about their claimed 4% default rate. Subsequently, we will see whether loans with higher grades have indeed higher interest rates and higher default rates. And we will close the exploration part with how profitable the loans with the different grade categories actually are on average. Hereafter we will move on to the prediction part. Where we will use Random Forest and Logistic Regression to predict the 'charged off' from the 'fully paid' loans. We will see if an algorithm with just grade performs just as good as an algorithm with all features. Hence that adding features gives no benefit from the metric Lending Club already provides. Furthermore, we will try to recreate grade from the features, to see whether Lending Club provides the features they use for their algorithm and which features are important because they are used to create grade. And finally, we will see whether return of investment increases with our algorithm and whether we can give some tips to the lending club investors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project the Lending Club dataset from Kaggle was used (https://www.kaggle.com/wendykan/lending-club-loan-data). This file contains complete loan data for loans issued between 2007 and 2015. There are 887,379 loans in the file and 74 features. A couple of features have to do with the loan (32) and a couple have to do with the one that's asking for the loan (42). The feature we are intested in to predict is 'loan status'. In this case we are only interested in loans that went to full term. Hence we selected the loans that had either status 'fully paid' or 'charged off'. Statusses 'issued', 'current', 'default', 'late (31-120 days)', 'late (16-30 days)' and 'in grace period' are loans that are still ongoing for which you cannot be certain yet how they ended. 'Does not meet credit policy' loans would not be issued today, so are not useful for future investors. In all the loans 5% has the status 'charged off'. After selecting only the loans that went to full term, we are left with 252,971 loans. This is 28.5% of the number of loans we started with. Of these 18% have the status 'charged off'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loans: (887379, 74)\n",
      "['Fully Paid' 'Charged Off' 'Current' 'Default' 'Late (31-120 days)'\n",
      " 'In Grace Period' 'Late (16-30 days)'\n",
      " 'Does not meet the credit policy. Status:Fully Paid'\n",
      " 'Does not meet the credit policy. Status:Charged Off' 'Issued']\n",
      "percentage charged off in all loans: 5.0 \n",
      "\n",
      "closed_loans: (252971, 74)\n",
      "precentage closed loans of total loans: 28.5\n",
      "percentage charged off in closed loans: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ro.d.bruijn/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (19,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('../data/loan.csv')\n",
    "print('loans:',loans.shape)\n",
    "print(loans['loan_status'].unique())\n",
    "print('percentage charged off in all loans:', \n",
    "      round(sum(loans['loan_status']=='Charged Off')/len(loans['loan_status'])*100), '\\n')\n",
    "\n",
    "# selecting loans that went to full term\n",
    "closed_loans = loans[loans['loan_status'].isin(['Fully Paid', 'Charged Off'])]\n",
    "print('closed_loans:',closed_loans.shape)\n",
    "print('precentage closed loans of total loans:', round(closed_loans.shape[0] / loans.shape[0] * 100, 1))\n",
    "print('percentage charged off in closed loans:', \n",
    "      round(sum(closed_loans['loan_status']=='Charged Off')/len(closed_loans['loan_status'])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to give advice to investors which loans they should invest in. Therefore we selected for the prediction only the features that are known before the investors pick the loans they want to invest in. Also we deleted features that are not useful for prediciton like 'id' and features that have all the same values. There was only one 'joint' loan application, while all others where individual loans. Hence we deleted this one loan also. If a feature had more than 10% missing features we deleted this feature from the features used for prediction. Moreover rows that had a missing value in one of the remaining features were deleted. The features 'earliest creditline' and 'issue date' were transformed to one feature, namely the number of days between the earliest creditline and the issue date of the loan (Rpub). The values in the feature annual income were divided by 1000 and rounded-up in order to get more similar values and outliers (above 200,000) were transformed to 200,000. After these tranformation we are left with 252,771 loans and 23 features and the percentage of 'charged off' loans is still 18%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252771, 23)\n",
      "percentage charged off in closed loans: 18.0\n"
     ]
    }
   ],
   "source": [
    "include = ['term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_length', 'home_ownership', \n",
    "          'annual_inc', 'purpose', 'zip_code', 'addr_state', 'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', \n",
    "          'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', \n",
    "          'mths_since_last_major_derog', 'acc_now_delinq', 'loan_amnt', 'open_il_6m', 'open_il_12m', \n",
    "          'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'dti', 'open_acc_6m', 'tot_cur_bal',\n",
    "          'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', 'total_cu_tl',\n",
    "          'inq_last_12m', 'issue_d', 'loan_status']\n",
    "\n",
    "# exclude the one joint application\n",
    "closed_loans = closed_loans[closed_loans['application_type'] == 'INDIVIDUAL']\n",
    "\n",
    "# make id index\n",
    "closed_loans.index = closed_loans.id\n",
    "\n",
    "# include only the features above\n",
    "closed_loans = closed_loans[include]\n",
    "\n",
    "# exclude features with more than 10% missing values\n",
    "columns_not_missing = (closed_loans.isnull().apply(sum, 0) / len(closed_loans)) < 0.1\n",
    "closed_loans = closed_loans.loc[:,columns_not_missing[columns_not_missing].index]\n",
    "\n",
    "# delete rows with NANs\n",
    "closed_loans = closed_loans.dropna()\n",
    "\n",
    "# calculate nr of days between earliest creditline and issue date of the loan\n",
    "# delete the two original features\n",
    "closed_loans['earliest_cr_line'] = pd.to_datetime(closed_loans['earliest_cr_line'])\n",
    "closed_loans['issue_d'] = pd.to_datetime(closed_loans['issue_d'])\n",
    "closed_loans['days_since_first_credit_line'] = closed_loans['issue_d'] - closed_loans['earliest_cr_line']\n",
    "closed_loans['days_since_first_credit_line'] = closed_loans['days_since_first_credit_line'] / np.timedelta64(1, 'D')\n",
    "closed_loans = closed_loans.drop(['earliest_cr_line', 'issue_d'], axis=1)\n",
    "\n",
    "# round-up annual_inc and cut-off outliers annual_inc at 200.000\n",
    "closed_loans['annual_inc'] = np.ceil(closed_loans['annual_inc'] / 1000)\n",
    "closed_loans.loc[closed_loans['annual_inc'] > 200, 'annual_inc'] = 200\n",
    "\n",
    "print(closed_loans.shape)\n",
    "print('percentage charged off in closed loans:', \n",
    "      round(sum(closed_loans['loan_status']=='Charged Off') / len(closed_loans['loan_status']) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected features:\n",
    "- term: the number of payments on the loan. Values are in months and can be either\n",
    "36 or 60\n",
    "- int_rate: interest rate\n",
    "- installment: height monthly pay\n",
    "- grade: A-G, A low risk, G high risk\n",
    "- sub_grade: A1-G5\n",
    "- emp_length: 0-10 years (10 stands for >=10)\n",
    "- home_ownership: 'RENT', 'OWN', 'MORTGAGE', 'OTHER', 'NONE' and 'ANY'\n",
    "- annual_inc: annual income stated by borrower, divided by 1000 and rounded-up, 200 stand for >=200,000\n",
    "- purpose: 'credit_card', 'car', 'small_business', 'other', 'wedding', 'debt_consolidation', 'home_improvement', 'major_purchase', 'medical', 'moving', 'vacation', 'house', 'renewable_energy' and 'educational'\n",
    "- zip_code: first 3 numbers followed by 2 times x\n",
    "- addr_state: two letters representing the state the borrower lives in\n",
    "- delinq_2yrs: the number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
    "- inq_last_6mths: the number of inquiries by creditors during the past 6 months\n",
    "- open acc: the number of open credit lines in the borrower’s credit file\n",
    "- pub_rec: number of derogatory public records\n",
    "- revol_bal: total credit revolving balance\n",
    "- revol_util: revolving line utilization rate, or the amount of credit the borrower is using\n",
    "relative to all available revolving credit\n",
    "- total_acc: the total number of credit lines currently in the borrower’s credit file\n",
    "- acc_now_delinq: the number of accounts on which the borrower is now delinquent\n",
    "- loan_amnt: the listed amount of the loan applied for by the borrower\n",
    "- dti: a ratio calculated using the borrower’s total monthly debt payments on the\n",
    "total debt obligations, excluding mortgage and the requested LC loan, divided\n",
    "by the borrower’s self-reported monthly income\n",
    "- loan_status: the listed amount of the loan applied for by the borrower\n",
    "- days_since_first_credit_line: self created feature, days between earliest creditline and issue date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_length',\n",
       "       'home_ownership', 'annual_inc', 'purpose', 'zip_code', 'addr_state',\n",
       "       'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal',\n",
       "       'revol_util', 'total_acc', 'acc_now_delinq', 'loan_amnt', 'dti',\n",
       "       'loan_status', 'days_since_first_credit_line'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_loans.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn the features have to be numerical that we input in this algorithm, so we need to convert the categorical features to numeric. To do this ordered categorical features will have adjacent numbers and unordered features will get an order as best as possible during conversion to numeric, for instance geographical. Also there cannot be nan/inf/-inf values, hence these will be made 0's. With this algorithm we will also have to scale and normalize the features.\n",
    "Non-numeric features were converted as follows:\n",
    "- grade/sub_grade: order of the letters was kept\n",
    "- emp_length: nr of years\n",
    "- zipcode: numbers kept of zipcode (geographical order)\n",
    "- term: in months\n",
    "- home_ownership: from none/any/other to rent to mortgage to owned\n",
    "- purpose: from purposes that might make money to purposes that only cost money\n",
    "- addr_state: ordered geographically from west to east, top to bottom (https://theusa.nl/staten/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features that are not float or int, so not to be converted:\n",
    "\n",
    "# ordered:\n",
    "# sub_grade, emp_length, zip_code, term\n",
    "\n",
    "# unordered:\n",
    "# home_ownership, purpose, addr_state (ordered geographically)\n",
    "\n",
    "closed_loans_predict = closed_loans\n",
    "\n",
    "# term\n",
    "closed_loans_predict['term'] = closed_loans_predict['term'].apply(lambda x: int(x.split(' ')[1]))\n",
    "\n",
    "# grade\n",
    "closed_loans_predict['grade'] = closed_loans_predict['grade'].astype('category')\n",
    "grade_dict = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n",
    "closed_loans_predict['grade'] = closed_loans_predict['grade'].apply(lambda x: grade_dict[x])\n",
    "\n",
    "# emp_length\n",
    "emp_length_dict = {'n/a':0,\n",
    "                   '< 1 year':0,\n",
    "                   '1 year':1,\n",
    "                   '2 years':2,\n",
    "                   '3 years':3,\n",
    "                   '4 years':4,\n",
    "                   '5 years':5,\n",
    "                   '6 years':6,\n",
    "                   '7 years':7,\n",
    "                   '8 years':8,\n",
    "                   '9 years':9,\n",
    "                   '10+ years':10}\n",
    "closed_loans_predict['emp_length'] = closed_loans_predict['emp_length'].apply(lambda x: emp_length_dict[x])\n",
    "\n",
    "# zipcode\n",
    "closed_loans_predict['zip_code'] = closed_loans_predict['zip_code'].apply(lambda x: int(x[0:3]))\n",
    "\n",
    "# subgrade\n",
    "closed_loans_predict['sub_grade'] = (closed_loans_predict['grade'] \n",
    "                                    + closed_loans_predict['sub_grade'].apply(lambda x: float(list(x)[1])/10))\n",
    "\n",
    "# house\n",
    "house_dict = {'NONE': 0, 'OTHER': 0, 'ANY': 0, 'RENT': 1, 'MORTGAGE': 2, 'OWN': 3}\n",
    "closed_loans_predict['home_ownership'] = closed_loans_predict['home_ownership'].apply(lambda x: house_dict[x])\n",
    "\n",
    "# purpose\n",
    "purpose_dict = {'other': 0, 'small_business': 1, 'renewable_energy': 2, 'home_improvement': 3,\n",
    "                'house': 4, 'educational': 5, 'medical': 6, 'moving': 7, 'car': 8, \n",
    "                'major_purchase': 9, 'wedding': 10, 'vacation': 11, 'credit_card': 12, \n",
    "                'debt_consolidation': 13}\n",
    "closed_loans_predict['purpose'] = closed_loans_predict['purpose'].apply(lambda x: purpose_dict[x])\n",
    "\n",
    "# states\n",
    "state_dict = {'AK': 0, 'WA': 1, 'ID': 2, 'MT': 3, 'ND': 4, 'MN': 5, \n",
    "              'OR': 6, 'WY': 7, 'SD': 8, 'WI': 9, 'MI': 10, 'NY': 11, \n",
    "              'VT': 12, 'NH': 13, 'MA': 14, 'CT': 15, 'RI': 16, 'ME': 17,\n",
    "              'CA': 18, 'NV': 19, 'UT': 20, 'CO': 21, 'NE': 22, 'IA': 23, \n",
    "              'KS': 24, 'MO': 25, 'IL': 26, 'IN': 27, 'OH': 28, 'PA': 29, \n",
    "              'NJ': 30, 'KY': 31, 'WV': 32, 'VA': 33, 'DC': 34, 'MD': 35, \n",
    "              'DE': 36, 'AZ': 37, 'NM': 38, 'OK': 39, 'AR': 40, 'TN': 41, \n",
    "              'NC': 42, 'TX': 43, 'LA': 44, 'MS': 45, 'AL': 46, 'GA': 47, \n",
    "              'SC': 48, 'FL': 49, 'HI': 50}\n",
    "closed_loans_predict['addr_state'] = closed_loans_predict['addr_state'].apply(lambda x: state_dict[x])\n",
    "\n",
    "# make NA's, inf and -inf 0\n",
    "closed_loans_predict = closed_loans_predict.fillna(0)\n",
    "closed_loans_predict = closed_loans_predict.replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected two algorithms to use for this project based on that they preformed the best on Lending Club datasets: Logistic Regression and Random Forest. The Logistic Regression classifier is a simple classifier that uses a sigmoidal curve to predict from the features to which class the sample belongs. It has one parameter to tune namely the C-parameter. This is the inverse of the regularization strength, smaller values specify stronger regularization. We will be using l1/lasso-regularization in the case of multiple features. With this algorithm we will also have to scale and normalize the features. Sometimes this algorithm has been found to perform better with less features on a Lending Club dataset.\n",
    "\n",
    "Random Forest is a more complicated algorithm that scores well in a lot of cases. This algorithm makes various decision trees from subsets of the samples and uses at each split only a fraction of the features to prevent overfitting. The Random Forest algorithm is known to be not very sensitive to the values of its parameters: the number of features used at each split and the number of trees in the forest. Nevertheless, the default of sklearn is so low that we will raise the number of trees to 100. The algorithm has feature selection already builtin (at each split) and scaling/normalization is also not necessary.\n",
    "\n",
    "For the classification we will split the data in a train (70%) and a test set (30%). The test set is used to evaluate the performance of our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data in train (70%) and test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(closed_loans_predict.drop('loan_status', axis=1), \n",
    "                                                    closed_loans_predict['loan_status'], \n",
    "                                                    test_size=0.3, random_state=123)\n",
    "\n",
    "# scaling and normalizing the features\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "# scale test set with scaling used in train set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a few metrics to test the performance of our classifier on the test set. First we will use confusion matrices and their statistics. A confusion matrix shows how many true negatives (TN), false positives (FP), false negatives (FN) and true positives (TP). Secondly, we will use the F-score. This is implemented as 'f1_weighted' in sklearn. This score can be interpreted as a weighted average of the precision and recall. Precision is defined as TP / (TP + FP), while recall is defined as TP / (TP + FN). The F-score is supposed to deal better with classes of unequal size, as is the case in this project, than the standard accuracy metric, which could become really high if the algorithm only predicts the dominant class. Lastly, we will show Receiver Operating Characteristic (ROC) curves which deal very well with unequal sized classes. The Area Under the Curve (AUC)-score of the ROC-plot is always 0.5 for random result and above 0.5 for a better than random result with 1.0 as maximum score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rpub, Stanford, Wu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
